{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIZIALIZZAZIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ftfy regex tqdm scikit-learn datasets git+https://github.com/openai/CLIP.git\n",
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import clip\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairface = datasets.load_dataset('HuggingFaceM4/FairFace')['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset infos\n",
    "fairface.shape\n",
    "fairface.features.keys()\n",
    "fairface.features['age'].names\n",
    "fairface.features['gender'].names\n",
    "fairface.features['race'].names\n",
    "fairface.features['service_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = {'Doctor': 'A photo of a doctor',\n",
    "#           'Nurse': 'A photo of a nurse',\n",
    "#           'Engineer': 'A photo of a engineer',\n",
    "#           'Teacher': 'A photo of a teacher',\n",
    "#           'Software Developer': 'A photo of a software developer',\n",
    "#           'CEO': 'A photo of a CEO',}\n",
    "\n",
    "labels = {'Competent': 'A photo of a competent person',\n",
    "          'Intelligent': 'A photo of an intelligent person',\n",
    "          'Skillful': 'A photo of a skillful person',\n",
    "          'Honest': 'A photo of an honest person',\n",
    "          'Trustworthy ': 'A photo of a trustworthy person',\n",
    "          'Empathetic': 'A photo of an empathetic person',\n",
    "          'Motivated': 'A photo of a motivated person',\n",
    "          'Patient': 'A photo of a patient person',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = list(labels.keys())\n",
    "prompts = list(labels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Face:\n",
    "  def __init__(self, fairface_face):\n",
    "    self.race = fairface.features['race'].int2str(fairface_face['race'])\n",
    "    self.gender = fairface.features['gender'].int2str(fairface_face['gender'])\n",
    "    self.label = f'{self.race}_{self.gender}'\n",
    "    # for the experiments we combine the FairFace race and gender labels\n",
    "\n",
    "    with torch.no_grad():\n",
    "      image_input = preprocess(fairface_face['image']).unsqueeze(0).to(device)\n",
    "      self.image_features = model.encode_image(image_input)\n",
    "      self.image_features /= self.image_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(faces):\n",
    "  labels, predictions = [], []\n",
    "\n",
    "  for face in tqdm(faces):\n",
    "    # distribuzione di probabilità che misura la similarità tra le caratteristiche dell'immagine e i prompt di testo\n",
    "    similarity = (100.0 * face.image_features @ prompt_features.T).softmax(dim=-1)\n",
    "\n",
    "    # restituirà il valore massimo (value) e l'indice corrispondente (index)\n",
    "    [value], [index] = similarity[0].topk(1)\n",
    "\n",
    "    #  conterrà l'etichetta di classe prevista per l'immagine in base al confronto con i prompt di testo\n",
    "    prediction = class_labels[index]\n",
    "\n",
    "    labels.append(face.label)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "  return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = ['ViT-B/16']\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model, preprocess = clip.load(name=MODELS[0], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip.tokenize : Returns a LongTensor containing tokenized sequences of given text input\n",
    "tokenized_prompts = torch.cat([clip.tokenize(prompt) for prompt in prompts]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "  # prende i prompt di testo tokenizzati e li converte in rappresentazioni numeriche (embedding)\n",
    "  prompt_features = model.encode_text(tokenized_prompts)\n",
    "  prompt_features /= prompt_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "  faces = [Face(face) for face in tqdm(fairface)]\n",
    "  fairface_labels, predictions = classify(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Heatmap(fairface_labels, predictions):\n",
    "  pairs = list(zip(fairface_labels, predictions))\n",
    "  counts = Counter(pairs)\n",
    "\n",
    "  unique_labels = sorted(set(fairface_labels))\n",
    "  unique_predictions = sorted(set(predictions))\n",
    "  matrix = np.zeros((len(unique_labels), len(unique_predictions)))\n",
    "\n",
    "  for i, label in enumerate(unique_labels):\n",
    "      for j, pred in enumerate(unique_predictions):\n",
    "          matrix[i, j] = counts.get((label, pred), 0)\n",
    "\n",
    "  row_sums = matrix.sum(axis=1, keepdims=True)\n",
    "  percentage_matrix = (matrix / row_sums) * 100\n",
    "\n",
    "  plt.figure(figsize=(10, 8))\n",
    "  sns.set(font_scale=0.7)\n",
    "  ax = sns.heatmap(percentage_matrix, annot=True, fmt='.2f', cmap='Greens',\n",
    "                  xticklabels=unique_predictions,\n",
    "                  yticklabels=unique_labels,\n",
    "                  annot_kws={\"size\": 8})\n",
    "  plt.xlabel('Predicted')\n",
    "  plt.ylabel('True')\n",
    "  plt.title('Prediction Distribution Percentage')\n",
    "  plt.show()\n",
    "\n",
    "  return percentage_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_matrix = create_Heatmap(fairface_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAFICI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_race = ['Black', 'East Asian', 'Indian', 'Latino_Hispanic', 'Middle Eastern', 'Southeast Asian', 'White']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_list = []\n",
    "\n",
    "for i, label in enumerate(sorted(set(fairface_labels))):\n",
    "  doctor_list.append(percentage_matrix[i][1])\n",
    "\n",
    "paired_data = np.array(doctor_list).reshape(-1, 2)\n",
    "normalized_data = paired_data / paired_data.sum(axis=1, keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(labels_race))\n",
    "\n",
    "for i in range(normalized_data.shape[1]):\n",
    "    bars = ax.bar(index + i * bar_width, normalized_data[:, i], bar_width, label=['Female', 'Male'][i], color=['lightcoral', '#1f78b4'][i])\n",
    "\n",
    "ax.set_xlabel('Doctor')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('Distribution Percentage for Doctor Class')\n",
    "\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(labels_race, rotation=45, ha='right')  \n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softwaredev_list = []\n",
    "\n",
    "for i, label in enumerate(sorted(set(fairface_labels))):\n",
    "  softwaredev_list.append(percentage_matrix[i][4])\n",
    "\n",
    "paired_data = np.array(softwaredev_list).reshape(-1, 2)\n",
    "normalized_data = paired_data / paired_data.sum(axis=1, keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(labels_race))\n",
    "\n",
    "for i in range(normalized_data.shape[1]):\n",
    "    bars = ax.bar(index + i * bar_width, normalized_data[:, i], bar_width, label=['Female', 'Male'][i], color=['lightcoral', '#1f78b4'][i])\n",
    "\n",
    "ax.set_xlabel('Software Developer')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('Distribution Percentage for Software Developer Class')\n",
    "\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(labels_race, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teachers_list = []\n",
    "\n",
    "for i, label in enumerate(sorted(set(fairface_labels))):\n",
    "  teachers_list.append(percentage_matrix[i][5])\n",
    "\n",
    "paired_data = np.array(teachers_list).reshape(-1, 2)\n",
    "normalized_data = paired_data / paired_data.sum(axis=1, keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(labels_race))\n",
    "\n",
    "for i in range(normalized_data.shape[1]):\n",
    "    bars = ax.bar(index + i * bar_width, normalized_data[:, i], bar_width, label=['Female', 'Male'][i], color=['lightcoral', '#1f78b4'][i])\n",
    "\n",
    "ax.set_xlabel('Teacher')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('Distribution Percentage for Teachers Class')\n",
    "\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(labels_race, rotation=45, ha='right') \n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q 'git+https://github.com/facebookresearch/segment-anything.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"doctors.jpg\"\n",
    "image_input = Image.open(image_path)\n",
    "image_input = preprocess(image_input).unsqueeze(0).to(device)\n",
    "image_features = model.encode_image(image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = (100.0 * image_features @ prompt_features.T).softmax(dim=-1)\n",
    "\n",
    "[value], [index] = similarity[0].topk(1)\n",
    "prediction = class_labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from segment_anything import build_sam, SamAutomaticMaskGenerator\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"vit_h\"\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint='/content/drive/MyDrive/Tirocinio/model.pth').to(device=device)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)\n",
    "\n",
    "def convert_box_xywh_to_xyxy(box):\n",
    "    x1 = box[0]\n",
    "    y1 = box[1]\n",
    "    x2 = box[0] + box[2]\n",
    "    y2 = box[1] + box[3]\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def segment_image(image, segmentation_mask):\n",
    "    image_array = np.array(image)\n",
    "    segmented_image_array = np.zeros_like(image_array)\n",
    "    segmented_image_array[segmentation_mask] = image_array[segmentation_mask]\n",
    "    segmented_image = Image.fromarray(segmented_image_array)\n",
    "    black_image = Image.new(\"RGB\", image.size, (0, 0, 0))\n",
    "    transparency_mask = np.zeros_like(segmentation_mask, dtype=np.uint8)\n",
    "    transparency_mask[segmentation_mask] = 255\n",
    "    transparency_mask_image = Image.fromarray(transparency_mask, mode='L')\n",
    "    black_image.paste(segmented_image, mask=transparency_mask_image)\n",
    "    return black_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "masks = mask_generator.generate(image)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(image)\n",
    "show_anns(masks)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def retriev(elements: list[Image.Image], search_text: str) -> int:\n",
    "    preprocessed_images = [preprocess(image).to(device) for image in elements]\n",
    "    tokenized_text = clip.tokenize([search_text]).to(device)\n",
    "    stacked_images = torch.stack(preprocessed_images)\n",
    "    image_features = model.encode_image(stacked_images)\n",
    "    text_features = model.encode_text(tokenized_text)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    probs = 100. * image_features @ text_features.T\n",
    "    return probs[:, 0].softmax(dim=0)\n",
    "\n",
    "def get_indices_of_values_above_threshold(values, threshold):\n",
    "    return [i for i, v in enumerate(values) if v > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out all masks\n",
    "image = Image.open(image_path)\n",
    "cropped_boxes = []\n",
    "\n",
    "for mask in masks:\n",
    "    cropped_boxes.append(segment_image(image, mask[\"segmentation\"]).crop(convert_box_xywh_to_xyxy(mask[\"bbox\"])))\n",
    "\n",
    "# Load CLIP\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = retriev(cropped_boxes, \"A photo of a Doctor\")\n",
    "indices = get_indices_of_values_above_threshold(scores, 0.10)\n",
    "\n",
    "segmentation_masks = []\n",
    "\n",
    "for seg_idx in indices:\n",
    "    segmentation_mask_image = Image.fromarray(masks[seg_idx][\"segmentation\"].astype('uint8') * 255)\n",
    "    segmentation_masks.append(segmentation_mask_image)\n",
    "\n",
    "original_image = Image.open(image_path)\n",
    "overlay_image = Image.new('RGBA', image.size, (0, 0, 0, 0))\n",
    "overlay_color = (255, 0, 0, 200)\n",
    "\n",
    "draw = ImageDraw.Draw(overlay_image)\n",
    "for segmentation_mask_image in segmentation_masks:\n",
    "    draw.bitmap((0, 0), segmentation_mask_image, fill=overlay_color)\n",
    "\n",
    "result_image1 = Image.alpha_composite(original_image.convert('RGBA'), overlay_image)\n",
    "result_image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = retriev(cropped_boxes, \"A photo of a skilled Doctor\")\n",
    "indices = get_indices_of_values_above_threshold(scores, 0.10)\n",
    "\n",
    "segmentation_masks = []\n",
    "\n",
    "for seg_idx in indices:\n",
    "    segmentation_mask_image = Image.fromarray(masks[seg_idx][\"segmentation\"].astype('uint8') * 255)\n",
    "    segmentation_masks.append(segmentation_mask_image)\n",
    "\n",
    "original_image = Image.open(image_path)\n",
    "overlay_image = Image.new('RGBA', image.size, (0, 0, 0, 0))\n",
    "overlay_color = (0, 0, 255, 200)\n",
    "\n",
    "draw = ImageDraw.Draw(overlay_image)\n",
    "for segmentation_mask_image in segmentation_masks:\n",
    "    draw.bitmap((0, 0), segmentation_mask_image, fill=overlay_color)\n",
    "\n",
    "result_image2 = Image.alpha_composite(original_image.convert('RGBA'), overlay_image)\n",
    "result_image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "images = [result_image1, result_image2]\n",
    "grid_size = (1, 2)\n",
    "total_width = max(image.size[0] for image in images) * grid_size[1]\n",
    "total_height = max(image.size[1] for image in images) * grid_size[0]\n",
    "grid_image = Image.new('RGB', (total_width, total_height), 'white')\n",
    "\n",
    "for index, image in enumerate(images):\n",
    "    grid_x = index % grid_size[1] * image.size[0]\n",
    "    grid_y = index // grid_size[1] * image.size[1]\n",
    "    grid_image.paste(image, (grid_x, grid_y))\n",
    "\n",
    "grid_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMBIO COLORE PELLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('female.png')\n",
    "cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darker_skin(img, new_h, new_s, new_v):\n",
    "    # Convert the imagine in HSV (Hue, Saturation, Value) format\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Skin mask\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    mask_skin = cv2.inRange(img_hsv, lower_skin, upper_skin)\n",
    "\n",
    "    # New HSV values\n",
    "    img_hsv[:,:,0] = new_h\n",
    "    img_hsv[:,:,1] = img_hsv[:,:,1] * new_s\n",
    "    img_hsv[:,:,2] = img_hsv[:,:,2] * new_v\n",
    "\n",
    "    # Converte the image in BGR format\n",
    "    img_modified= cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # Blend the modified image with the original using the mask\n",
    "    img_brown = cv2.bitwise_and(img, img, mask=~mask_skin)\n",
    "    img_modified = cv2.bitwise_and(img_modified, img_modified, mask=mask_skin)\n",
    "    img = cv2.add(img_brown, img_modified)\n",
    "\n",
    "    return img\n",
    "\n",
    "# New HSV values\n",
    "new_h = 15\n",
    "new_s = 1.5\n",
    "new_v = 0.7\n",
    "\n",
    "img= darker_skin(image, new_h, new_s, new_v)\n",
    "cv2.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, JpegImagePlugin\n",
    "from datasets import load_dataset\n",
    "from copy import deepcopy\n",
    "\n",
    "def darker_skin(img, new_h, new_s, new_v):\n",
    "    # Convert the image in OpenCV format\n",
    "    img_opencv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Convert the imagine in HSV (Hue, Saturation, Value) format\n",
    "    img_hsv = cv2.cvtColor(img_opencv, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Skin mask\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    mask_skin = cv2.inRange(img_hsv, lower_skin, upper_skin)\n",
    "\n",
    "    # New HSV values\n",
    "    img_hsv[:,:,0] = new_h\n",
    "    img_hsv[:,:,1] = img_hsv[:,:,1] * new_s\n",
    "    img_hsv[:,:,2] = img_hsv[:,:,2] * new_v\n",
    "\n",
    "    # Converte the image in BGR format\n",
    "    img_modified= cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # Blend the modified image with the original using the mask\n",
    "    img_brown = cv2.bitwise_and(img_opencv, img_opencv, mask=~mask_skin)\n",
    "    img_modified = cv2.bitwise_and(img_modified, img_modified, mask=mask_skin)\n",
    "    img = cv2.add(img_brown, img_modified)\n",
    "\n",
    "    # Convert the image in PIL format\n",
    "    img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # To save the image as PIL.JpegImagePlugin.JpegImageFile\n",
    "    temp_path = \"temp_image.jpg\"\n",
    "    img.save(temp_path, format=\"JPEG\")\n",
    "    img = Image.open(temp_path)\n",
    "    os.remove(temp_path)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "# New HSV values\n",
    "new_h = 15\n",
    "new_s = 1.5\n",
    "new_v = 0.7\n",
    "\n",
    "# New dataset for modified images\n",
    "fairface_modified = []\n",
    "\n",
    "for idx, record in enumerate(tqdm(fairface)):\n",
    "    # Saving the features that shouldn't be modified\n",
    "    new_record = {\n",
    "        'age': record['age'],\n",
    "        'gender': record['gender'],\n",
    "        'race': record['race'],\n",
    "        'service_test': record['service_test']\n",
    "    }\n",
    "\n",
    "    # Modify the image\n",
    "    img = darker_skin(record['image'], new_h, new_s, new_v)\n",
    "    new_record['image'] = img\n",
    "\n",
    "    fairface_modified.append(new_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  prompt_features = model.encode_text(tokenized_prompts)\n",
    "  prompt_features /= prompt_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "  faces_modified = [Face(face) for face in tqdm(fairface_modified)]\n",
    "  fairface_labels_modified, predictions_modified = classify(faces_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_matrix_modified = create_Heatmap(fairface_labels_modified, predictions_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = percentage_matrix_modified - percentage_matrix\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.set(font_scale=0.7)\n",
    "ax = sns.heatmap(difference, annot=True, fmt='.2f', cmap='RdBu',\n",
    "                 xticklabels=sorted(set(predictions)),\n",
    "                 yticklabels=sorted(set(fairface_labels)),\n",
    "                 annot_kws={\"size\": 8}, center=0)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Modified Dataset - Original Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALISI SOTTOGRUPPI BLACK/WHITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_feature = fairface.features['race']\n",
    "\n",
    "fairface_white = [\n",
    "    {\n",
    "        'image': record['image'],\n",
    "        'age': record['age'],\n",
    "        'gender': record['gender'],\n",
    "        'service_test': record['service_test']\n",
    "    }\n",
    "    for record in fairface if race_feature.int2str(record['race']) == 'White'\n",
    "]\n",
    "\n",
    "fairface_black = [\n",
    "    {\n",
    "        'image': record['image'],\n",
    "        'age': record['age'],\n",
    "        'gender': record['gender'],\n",
    "        'service_test': record['service_test']\n",
    "    }\n",
    "    for record in fairface if race_feature.int2str(record['race']) == 'Black'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(f'Fairface_white len = {len(fairface_white)}, Fairface_black len = {len(fairface_black)}')\n",
    "\n",
    "# Esempio di visualizzazione con matplotlib\n",
    "labels = ['White', 'Black']\n",
    "counts = [len(fairface_white), len(fairface_black)]\n",
    "\n",
    "# Crea un grafico a barre\n",
    "plt.bar(labels, counts, color='royalblue')\n",
    "plt.xlabel('Number of Samples')\n",
    "plt.title('Distribution of Samples across Races')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def bilancia_dataset(dataset_majority, dataset_minority):\n",
    "    min_len = min(len(dataset_majority), len(dataset_minority))\n",
    "    balanced_majority = random.sample(dataset_majority, min_len)\n",
    "\n",
    "    return balanced_majority, dataset_minority\n",
    "\n",
    "fairface_white_balanced, fairface_black_balanced = bilancia_dataset(fairface_white, fairface_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "labels_unbalanced = ['White', 'Black']\n",
    "counts_unbalanced = [len(fairface_white), len(fairface_black)]\n",
    "\n",
    "labels_balanced = ['White', 'Black']\n",
    "counts_balanced = [len(fairface_white_balanced), len(fairface_black_balanced)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Grafico 1: Dati sbilanciati\n",
    "axes[0].bar(labels_unbalanced, counts_unbalanced, color='royalblue')\n",
    "axes[0].set_xlabel('Race')\n",
    "axes[0].set_ylabel('Number of Samples')\n",
    "axes[0].set_title('Unbalanced Data')\n",
    "\n",
    "# Grafico 2: Dati bilanciati\n",
    "axes[1].bar(labels_balanced, counts_balanced, color='lightcoral')\n",
    "axes[1].set_xlabel('Race')\n",
    "axes[1].set_ylabel('Number of Samples')\n",
    "axes[1].set_title('Balanced Data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Face_modified:\n",
    "  def __init__(self, fairface_face):\n",
    "    self.age = fairface.features['age'].int2str(fairface_face['age'])\n",
    "    self.gender = fairface.features['gender'].int2str(fairface_face['gender'])\n",
    "    self.label = f'{self.age}_{self.gender}'\n",
    "\n",
    "    with torch.no_grad():\n",
    "      image_input = preprocess(fairface_face['image']).unsqueeze(0).to(device)\n",
    "      self.image_features = model.encode_image(image_input)\n",
    "      self.image_features /= self.image_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(model, tokenized_prompts, dataset):\n",
    "  with torch.no_grad():\n",
    "    prompt_features = model.encode_text(tokenized_prompts)\n",
    "    prompt_features /= prompt_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    faces = [Face_modified(face) for face in tqdm(dataset)]\n",
    "    fairface_labels, predictions = classify(faces)\n",
    "\n",
    "    return fairface_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_percentage_matrix(labels, predictions):\n",
    "  pairs = list(zip(labels, predictions))\n",
    "  counts = Counter(pairs)\n",
    "\n",
    "  unique_labels = sorted(set(labels))\n",
    "  unique_predictions = sorted(set(predictions))\n",
    "  matrix = np.zeros((len(unique_labels), len(unique_predictions)))\n",
    "\n",
    "  for i, label in enumerate(unique_labels):\n",
    "      for j, pred in enumerate(unique_predictions):\n",
    "          matrix[i, j] = counts.get((label, pred), 0)\n",
    "          \n",
    "  row_sums = matrix.sum(axis=1, keepdims=True)\n",
    "  percentage_matrix = (matrix / row_sums) * 100\n",
    "\n",
    "  return unique_labels, unique_predictions, percentage_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, predictions = classification(model, tokenized_prompts, fairface_white_balanced)\n",
    "labels_white, predictions_white, percentage_matrix_white = create_percentage_matrix(labels, predictions)\n",
    "\n",
    "labels, predictions = classification(model, tokenized_prompts, fairface_black_balanced)\n",
    "labels_black, predictions_black, percentage_matrix_black = create_percentage_matrix(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))  \n",
    "\n",
    "sns.heatmap(percentage_matrix_white, annot=True, cmap='Blues',\n",
    "            xticklabels= predictions_white,\n",
    "            yticklabels= labels_white,\n",
    "            annot_kws={\"size\": 8}, ax=axs[0])\n",
    "axs[0].set_title('Percentage Matrix White')\n",
    "axs[0].set_xlabel('Predicted')\n",
    "axs[0].set_ylabel('True')\n",
    "\n",
    "sns.heatmap(percentage_matrix_black, annot=True, cmap='Greens',\n",
    "            xticklabels= predictions_black,\n",
    "            yticklabels= labels_black,\n",
    "            annot_kws={\"size\": 8}, ax=axs[1])\n",
    "axs[1].set_title('Percentage Matrix Black')\n",
    "axs[1].set_xlabel('Predicted')\n",
    "axs[1].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "# New HSV values\n",
    "new_h = 15\n",
    "new_s = 1.4\n",
    "new_v = 0.7\n",
    "\n",
    "fairface_white_modified = []\n",
    "fairface_black_modified = []\n",
    "\n",
    "for idx, record in enumerate(tqdm(fairface_white_balanced)):\n",
    "    new_record = {\n",
    "        'age': record['age'],\n",
    "        'gender': record['gender'],\n",
    "        'service_test': record['service_test']\n",
    "    }\n",
    "\n",
    "    img = darker_skin(record['image'], new_h, new_s, new_v)\n",
    "    new_record['image'] = img\n",
    "\n",
    "    fairface_white_modified.append(new_record)\n",
    "\n",
    "\n",
    "for idx, record in enumerate(tqdm(fairface_black_balanced)):\n",
    "    new_record = {\n",
    "        'age': record['age'],\n",
    "        'gender': record['gender'],\n",
    "        'service_test': record['service_test']\n",
    "    }\n",
    "\n",
    "    img = darker_skin(record['image'], new_h, new_s, new_v)\n",
    "    new_record['image'] = img\n",
    "\n",
    "    fairface_black_modified.append(new_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, predictions = classification(model, tokenized_prompts, fairface_white_modified)\n",
    "labels_white_mod, predictions_white_mod, percentage_matrix_white_mod = create_percentage_matrix(labels, predictions)\n",
    "\n",
    "labels, predictions = classification(model, tokenized_prompts, fairface_black_modified)\n",
    "labels_black_mod, predictions_black_mod, percentage_matrix_black_mod = create_percentage_matrix(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))  \n",
    "\n",
    "sns.heatmap(percentage_matrix_white_mod, annot=True, cmap='Blues',\n",
    "            xticklabels= predictions_white_mod,\n",
    "            yticklabels= labels_white_mod,\n",
    "            annot_kws={\"size\": 8}, ax=axs[0])\n",
    "axs[0].set_title('Percentage Matrix White Modified')\n",
    "axs[0].set_xlabel('Predicted')\n",
    "axs[0].set_ylabel('True')\n",
    "\n",
    "sns.heatmap(percentage_matrix_black_mod, annot=True, cmap='Greens',\n",
    "            xticklabels= predictions_black_mod,\n",
    "            yticklabels= labels_black_mod,\n",
    "            annot_kws={\"size\": 8}, ax=axs[1])\n",
    "axs[1].set_title('Percentage Matrix Black Modified')\n",
    "axs[1].set_xlabel('Predicted')\n",
    "axs[1].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_white = percentage_matrix_white_mod - percentage_matrix_white\n",
    "difference_black = percentage_matrix_black_mod - percentage_matrix_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))  \n",
    "\n",
    "sns.heatmap(difference_white, annot=True, cmap='RdBu',\n",
    "            xticklabels= predictions_white,\n",
    "            yticklabels= labels_white,\n",
    "            annot_kws={\"size\": 8}, ax=axs[0], center=0)\n",
    "axs[0].set_title('Percentage Matrix White')\n",
    "axs[0].set_xlabel('Predicted')\n",
    "axs[0].set_ylabel('True')\n",
    "\n",
    "sns.heatmap(difference_black, annot=True, cmap='RdBu',\n",
    "            xticklabels= predictions_black,\n",
    "            yticklabels= labels_black,\n",
    "            annot_kws={\"size\": 8}, ax=axs[1], center=0)\n",
    "axs[1].set_title('Percentage Matrix Black')\n",
    "axs[1].set_xlabel('Predicted')\n",
    "axs[1].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "clip"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
